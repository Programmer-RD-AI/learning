{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04-transfer-learning-in-tensorflow-part-1-feature-extraction.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1i7PlhTKfIPEJxEENdqe4fWJJf-XDnZZ0","authorship_tag":"ABX9TyOaz2mQwgZmOcwWVU4hLvKi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5toBai7QdDQ6"},"source":["# Transfer Learning with Tensorflow Part 1 : Feature Extraction\n","\n","Transfer learning is leveraging a working models exisiting architecture and learned patterns\n","\n","Benifits\n","- Can leverage an exsting NN architecture proven to work\n","- Can leverage a working NN which has already learned the patterns and we can adapt the patterns our problem"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjrl-cr-emak","executionInfo":{"status":"ok","timestamp":1616733281467,"user_tz":-330,"elapsed":971,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"9206c1a6-439a-4927-ff2b-cdd2049822c1"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Crfm2O0WefV4"},"source":["## Downloading and becomming one with the data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2cscgKTeutQ","executionInfo":{"status":"ok","timestamp":1616733283112,"user_tz":-330,"elapsed":2606,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"fb83a0a9-a081-41c0-de44-b3ea49577209"},"source":["!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-26 04:34:41--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 173.194.218.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 168546183 (161M) [application/zip]\n","Saving to: ‘10_food_classes_10_percent.zip.1’\n","\n","10_food_classes_10_ 100%[===================>] 160.74M   173MB/s    in 0.9s    \n","\n","2021-03-26 04:34:42 (173 MB/s) - ‘10_food_classes_10_percent.zip.1’ saved [168546183/168546183]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZFnVespeu9i","executionInfo":{"status":"ok","timestamp":1616733869490,"user_tz":-330,"elapsed":588979,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"92896fca-e0c3-41e0-d015-ea31febda627"},"source":["!unzip 10_food_classes_10_percent.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  10_food_classes_10_percent.zip\n","replace __MACOSX/._10_food_classes_10_percent? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6E-flEDbe7vu"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKRUxV4xfH1y","executionInfo":{"status":"ok","timestamp":1616733869504,"user_tz":-330,"elapsed":588985,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"34a1b270-3d3b-4ddd-9931-7eb5dcb2d33a"},"source":["# How many images in each folder ? \n","# Walk through 10% data dir and list number of files\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 2 directories and 0 images in '10_food_classes_10_percent'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n","There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mAv4Su4efmLF"},"source":["## Create data loaders (preparing the data)\n","\n","We'll use the ImageDataGenerator class to load our images in batches"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ldMZey5gDb8","executionInfo":{"status":"ok","timestamp":1616733870109,"user_tz":-330,"elapsed":589586,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"34603d87-a009-4ac7-d2c7-7f936b2844bd"},"source":["# Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","IMAGE_SHAPE = (224,224)\n","BATCH_SIZE = 32\n","train_dir = \"10_food_classes_10_percent/train\"\n","test_dir = \"10_food_classes_10_percent/test\"\n","train_datagen = ImageDataGenerator(rescale=1/255.0)\n","test_datagen = ImageDataGenerator(rescale=1/255.0)\n","print('Training Images')\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,target_size=IMAGE_SHAPE)\n","print('Testing Images')\n","test_data_10_percent = test_datagen.flow_from_directory(test_dir,target_size=IMAGE_SHAPE)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Images\n","Found 750 images belonging to 10 classes.\n","Testing Images\n","Found 2500 images belonging to 10 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h3BzIEkxgpQs"},"source":["## Setting up callbacks (things to run while our model trains)\n","\n","Callbacks are extra funtionality you can add to your model to be performed during or after training. Some of the most popular callbacks:\n","\n","* Tracking experiments (Tensorboard)\n","* Model check point (ModelCheckpoint)\n","* Stop overfitting (EarlyStopping)"]},{"cell_type":"code","metadata":{"id":"Rl4LAixbkE0-"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WASprUsiX3N"},"source":["\n","# Create TensorBoard callback (functionized beause we need to create a new one for each model)\n","import datetime\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aa4ZRizKjUc"},"source":["## Creating models using tensorflow hub\n","\n","So in the past we have used tensorflow to make models from sctrach but now we are going to do a same like proccess but the architecture is coming from https://tfhub.dev/\n","\n","Browsing the Tensorflow hub page we found the following model (feature vector)\n","https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"]},{"cell_type":"code","metadata":{"id":"AFO7egznKx61"},"source":["# Lets compare the following 2 models\n","resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n","efficentnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b-kJFhm9TG0m"},"source":["# Import dependencies\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m_PBsiRcTeEY"},"source":["# Lets make a create_model funtion to create a model from a url\n","def create_model(model_url,num_classes=10):\n","  feature_extractor_layer = hub.KerasLayer(model_url,\n","                                          trainable=False, # remove all of the trained patterns\n","                                          name=\"feature_extraction_layer\",\n","                                          input_shape=(224,224,3)\n","                                           )\n","  model = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(num_classes,activation='softmax')\n","  ])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2YzsuRz6TkW5"},"source":["# Create and testing resnet tensorflow hub feature extraction model\n","resnet_model = create_model(resnet_url,num_classes=train_data_10_percent.num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HdofuNvnVtW-","executionInfo":{"status":"ok","timestamp":1616742163400,"user_tz":-330,"elapsed":893,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"1c468676-e354-4dad-b517-b27c333ecf76"},"source":["resnet_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","feature_extraction_layer (Ke (None, 2048)              23564800  \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                20490     \n","=================================================================\n","Total params: 23,585,290\n","Trainable params: 20,490\n","Non-trainable params: 23,564,800\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YwHEMKUCV6AD"},"source":["# Compiel our resnet moel\n","resnet_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNl77fibWNGw","executionInfo":{"status":"ok","timestamp":1616744775241,"user_tz":-330,"elapsed":2160249,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"778ad45d-c75f-4a9d-dda0-546a46558741"},"source":["resnet_model.fit(train_data_10_percent,epochs=5,callbacks=[create_tensorboard_callback('tensorflow_hub','resnet50v2')],validation_data=test_data_10_percent,)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving TensorBoard log files to: tensorflow_hub/resnet50v2/20210326-071015\n","Epoch 1/5\n","24/24 [==============================] - 435s 19s/step - loss: 2.2868 - accuracy: 0.2372 - val_loss: 1.2030 - val_accuracy: 0.6124\n","Epoch 2/5\n","24/24 [==============================] - 432s 19s/step - loss: 1.0109 - accuracy: 0.7096 - val_loss: 0.8469 - val_accuracy: 0.7396\n","Epoch 3/5\n","24/24 [==============================] - 434s 19s/step - loss: 0.6083 - accuracy: 0.8281 - val_loss: 0.7434 - val_accuracy: 0.7644\n","Epoch 4/5\n","24/24 [==============================] - 430s 19s/step - loss: 0.4686 - accuracy: 0.8672 - val_loss: 0.7003 - val_accuracy: 0.7772\n","Epoch 5/5\n","24/24 [==============================] - 427s 18s/step - loss: 0.4231 - accuracy: 0.8962 - val_loss: 0.6723 - val_accuracy: 0.7848\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4e66569fd0>"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"8h_7Zs40Wlee"},"source":["Wow ! \n","\n","That is incrediable. Our transfer learning feature extractor model out performs ALL of the previous models we built by hand. and with a quicker time and with only 10% of the training examples"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVEW7R5DZJRs","executionInfo":{"status":"ok","timestamp":1616745363304,"user_tz":-330,"elapsed":330851,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"bd0e2b4d-2153-4ace-b31f-6c6a060f3bcb"},"source":["import pandas as pd\n","preds = pd.DataFrame(resnet_model.evaluate(test_data_10_percent))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["79/79 [==============================] - 330s 4s/step - loss: 0.6723 - accuracy: 0.7848\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"ilcInkMBjOK3","executionInfo":{"status":"ok","timestamp":1616746427484,"user_tz":-330,"elapsed":1075,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"527b560b-4478-490b-dd79-57bc43186fa6"},"source":["preds"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.672322</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.784800</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0\n","0  0.672322\n","1  0.784800"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"1tfVOTjug4lV"},"source":["## Creating and testing EfficentNetB0 Tensorflow hub feature extraction model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UxjlF01hpAu","executionInfo":{"status":"ok","timestamp":1616746426392,"user_tz":-330,"elapsed":1058683,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"9ebd50de-8ed6-4d28-a02b-88435d4e5319"},"source":["efficent_model = create_model(efficentnet_url)\n","efficent_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\n","efficent_history = efficent_model.fit(train_data_10_percent,epochs=5,callbacks=[create_tensorboard_callback('tensorflow_hub','efficentnetb0')],validation_data=test_data_10_percent,)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving TensorBoard log files to: tensorflow_hub/efficentnetb0/20210326-075619\n","Epoch 1/5\n","24/24 [==============================] - 221s 9s/step - loss: 2.0921 - accuracy: 0.2906 - val_loss: 1.3130 - val_accuracy: 0.7360\n","Epoch 2/5\n","24/24 [==============================] - 208s 9s/step - loss: 1.1645 - accuracy: 0.7476 - val_loss: 0.8707 - val_accuracy: 0.8156\n","Epoch 3/5\n","24/24 [==============================] - 206s 9s/step - loss: 0.7697 - accuracy: 0.8586 - val_loss: 0.7001 - val_accuracy: 0.8408\n","Epoch 4/5\n","24/24 [==============================] - 205s 9s/step - loss: 0.6286 - accuracy: 0.8766 - val_loss: 0.6144 - val_accuracy: 0.8540\n","Epoch 5/5\n","24/24 [==============================] - 206s 9s/step - loss: 0.5226 - accuracy: 0.9100 - val_loss: 0.5584 - val_accuracy: 0.8612\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yYq9mS0FjT_A"},"source":["pd.DataFrame(efficent_model.evaluate(test_data_10_percent))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b21_5giFlsbK","executionInfo":{"status":"ok","timestamp":1616746751203,"user_tz":-330,"elapsed":971,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"669521aa-d927-4a14-ddf2-3db6537ae343"},"source":["efficent_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","feature_extraction_layer (Ke (None, 1280)              4049564   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                12810     \n","=================================================================\n","Total params: 4,062,374\n","Trainable params: 12,810\n","Non-trainable params: 4,049,564\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7ccA9sNnaCh","executionInfo":{"status":"ok","timestamp":1616746797182,"user_tz":-330,"elapsed":871,"user":{"displayName":"Ranuga D","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjuad_FPjQJNXxoJSYMZXSIw2XPL4E9xtpdkS1NEQ=s64","userId":"01133442572951588905"}},"outputId":"1dbd37d1-6105-4583-c75f-cd10e2eabdd4"},"source":["resnet_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","feature_extraction_layer (Ke (None, 2048)              23564800  \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                20490     \n","=================================================================\n","Total params: 23,585,290\n","Trainable params: 20,490\n","Non-trainable params: 23,564,800\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DW5jdlYbnlSS"},"source":["## Different types of transger learning\n","\n","* \"AS if\" transfer learning - using an existing model with no change what so ever\n","* \"Feature Extraction\" transfer learning - us the pre learned pattern of an existing model\n","* \"Find tuning\" transfer learning - use the pretrane model and fine tune the underlying layers"]},{"cell_type":"markdown","metadata":{"id":"XRmU4mQZnxR3"},"source":["## Comparing our models results using Tensorboard\n","\n","> Warning : When you upload things to tensorboard.dev your experiments are public so if you are running private experiments (things you dont want others to see) dont use tensorboard !!!!"]},{"cell_type":"code","metadata":{"id":"p3uFpcOrqp-5"},"source":["\n","# Upload TensorBoard dev records\n","!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","  --name \"EfficientNetB0 vs. ResNet50V2\" \\\n","  --description \"Comparing two different TF Hub feature extraction model architectures using 10% of the training data\" \\\n","  --one_shot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQmorkOUsz6b"},"source":["# Link https://tensorboard.dev/experiment/dQBrpdwIRgS2qI0Andv8Yg/#scalars"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g7kJ6Gqrt01V"},"source":["!tensorboard dev list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdGU8iyHs92W"},"source":["# Delete\n","# !tensorboard dev delete --experiment_id "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeV0PZR7tz7z"},"source":["!tensorboard dev list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1DEQaa0Bt-Tm"},"source":[""],"execution_count":null,"outputs":[]}]}